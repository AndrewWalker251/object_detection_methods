{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faster R-CNN\n",
    "\n",
    "The intention of this notebook is to provide the pipeline to quickly implement easily available YOLOv5 implementations on your own problem datasets.\n",
    "\n",
    "## Faster R-CNN How it works\n",
    "\n",
    "Important point to note about object detection. A challenge in image work is that usually you have convolution layers that are then connected to a fully connected layer. To make your model work, this means the size of the input image always needs to be fixed to a specific size. The same idea applies to object detection with the idea of the number of objects you're trying to detect. You can mess up the configuration of the model in the same way. \n",
    "\n",
    "Best blog i've found so far. Need to summarise.\n",
    "https://tryolabs.com/blog/2018/01/18/faster-r-cnn-down-the-rabbit-hole-of-modern-object-detection/\n",
    "\n",
    "Main sections:\n",
    "1) CNN - standard initial CNN. Often this can be a standard pretrained option such as ResNet. Take intermediate layer as output.\n",
    "2) RPN - Region proposal network - Finds a predefined number of regions (boxes) that might have an object in them. \n",
    "3) RoiP - Region of interest Pooling - pulls out these regions\n",
    "4) R-CNN - Predicts the class and the final bounding box for the object in these regions. \n",
    "\n",
    "A little further detail\n",
    "\n",
    "1) CNN - As you're taking an intermediate layer of the CNN you're taking only after the convolutions. So you've basically encoded the information in the image but retained the spacial relations. \n",
    "\n",
    "2) RPN. Anchors - fixed bounding boxes that are placed throughout the image with different sizes and ratios. The RPN then predicts for each anchor whether it thinks there is an object there (doesn't care about class yet) and the  the offset from the anchor box. deltax, deltay, deltawidth, deltaheight. After a convolution layer we then have two paralel convolutions, one provides a classification predicting two numbers per anchor (background score, object score) and the other a regression output for the bounding box adjustments. \n",
    "\n",
    "training - uses IoU threshold to say what is foreground object and what is background. It then uses a binary cross entropy to train on this.  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
